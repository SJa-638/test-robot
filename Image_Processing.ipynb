{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJa-638/test-robot/blob/main/Image_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **To Download the needed Libaries Exceute the following Commands**"
      ],
      "metadata": {
        "id": "xY8Nnge1sbEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "Uv0HOezq6YHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "Y6SHfMrTEEXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "whRDWUoYmvAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install git"
      ],
      "metadata": {
        "id": "guA7SxuFskhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Connecting to The Google drive to get The dataset**"
      ],
      "metadata": {
        "id": "s_aCHvOhAc61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1nxQpS5yXXzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Garabage Clssification Dataset](https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification/data)"
      ],
      "metadata": {
        "id": "YD0gbiHkN2o2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Libraries"
      ],
      "metadata": {
        "id": "ymTYqdYSNyEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "xwNokR-gmrO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow\n",
        "[TensorFlow For Beginnera](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb)\n",
        "*VERY IMP NOTE ON DOWNLOADING TENSORFLOW ON YOUR LOCAL COMPUTER BE CAREFUL ABOUT USING PIP TO INSTALL IT AND MAKE SURE VERSIONS OF PYTHON TENSORFLOW AND PIP ARE RIGHT OTHERWISE IT WON'T BE RECOGNIZED BY THE COMPUTER / OR DOWNLOAD IT MANUALLY FOLLOWING A TUTORIAL/ OR USE IT ON GOOGLE COLAB IT MAINTAINS THESE ERRORS*\n",
        "1. **Collect a dataset of images of garbage, labeled with the type of garbage.** You can either collect this dataset yourself or use a pre-existing dataset. Some pre-existing datasets that you can use include:\n",
        "    - TrashNet\n",
        "    - RecycleNet\n",
        "    - Google AI CircularNet dataset\n",
        "2. **Split the dataset into training and test sets.** The training set will be used to train the model, and the test set will be used to evaluate the performance of the model on unseen data. A common split is to use 80% of the dataset for training and 20% of the dataset for testing.\n",
        "3. **Preprocess the images.** This may involve resizing the images to a consistent size, normalizing the pixel values, and/or cropping the images to focus on the garbage item.\n",
        "4. **Choose a model architecture.** There are a number of different TensorFlow model architectures that you can use for garbage classification. Some popular choices include:\n",
        "    - ResNet\n",
        "    - MobileNet\n",
        "    - EfficientNet\n",
        "    - VGG16\n",
        "5. **Compile the model.** This involves specifying the loss function, optimizer, and learning rate.\n",
        "6. **Train the model.** This involves feeding the training images to the model and updating the model parameters to minimize the loss function.\n",
        "7. **Evaluate the model.** This involves feeding the test images to the model and measuring the accuracy of the model's predictions.\n",
        "8. **Save the model.** Once you are satisfied with the performance of the model, you can save it to a file. This will allow you to load the model later and use it to classify new images of garbage."
      ],
      "metadata": {
        "id": "_NQtckUSBB2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial For tensorflow\n",
        "[link text](https://www.youtube.com/watch?v=CMu25mtyl-s)"
      ],
      "metadata": {
        "id": "tIX5d80vS1og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/content/drive/MyDrive/dataset/Garbage_classification/Garbage_classification'\n",
        "trainGarabge = '/content/drive/MyDrive/dataset/Garbage_classification/Garbage_classification'\n",
        "valdData = '/content/drive/MyDrive/dataset/Garbage_classification/Garbage_classification'\n",
        "# Navigate to the directory where the dataset is uploaded\n",
        "os.chdir(trainGarabge)\n",
        "os.chdir(valdData)\n",
        "\n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset)\n",
        "# Load the dataset into Keras\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    trainGarabge,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        ")\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    valdData,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93dUn2TR31J",
        "outputId": "1c210cfb-ae2c-4937-e0e8-ae8994c712c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2527 files belonging to 6 classes.\n",
            "Found 2527 files belonging to 6 classes.\n",
            "Using 2022 files for training.\n",
            "Found 2527 files belonging to 6 classes.\n",
            "Using 505 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tds\n",
        "\n",
        "# Defining batch size and image labels\n",
        "\n",
        "batch_size = 64\n",
        "dataset_name = dataset\n",
        "class_names = dataset.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzWS20MxSUEU",
        "outputId": "04652267-b7fb-4769-a4ae-af7670a239d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = (512,512)\n",
        "#TO be Continued\n",
        "ds_train = trainGarabge.map(lambda image, label:(tf.image.resize(image,size),label)\n",
        "ds_vald = valdData.map(lambda image, label:(tf.image.resize(image,size),label)\n"
      ],
      "metadata": {
        "id": "WciofR0UTis6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1c3zgq_UiC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "abe0d4eb-f776-42b7-ca80-8fcbd10d9422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2527 files belonging to 6 classes.\n",
            "Found 2527 files belonging to 6 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-c0ed42805998>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# TO DO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainGarabge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'garbage'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# Add convolutional layers\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output of the convolutional layers\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# TO DO\n",
        "model.fit(trainGarabge,'garbage',epochs=10,validation_data=test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "# Save the model\n",
        "model.save('garbage_model.h5')\n",
        "\n",
        "# Load the trained TensorFlow model\n",
        "model = tf.keras.models.load_model('garbage_classifier.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "xh23fWFmDQGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo chown root:root ~/.kaggle\n",
        "!sudo chown root:root ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "-6pK1XKbDY8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo chmod 600 ~/.kaggle\n",
        "!sudo chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "CK0engmXDba8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "# Set up the Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Path to the downloaded dataset\n",
        "dataset_path = 'D:\\Kaggle dataset archive.zip'  # Path to the extracted dataset files\n",
        "\n",
        "# Download the Kaggle dataset\n",
        "dataset_name = 'lkihjh777'  # Replace with the name of the Kaggle dataset you want to download\n",
        "#api.dataset_download_files(dataset_name, path=dataset_path, unzip=True)\n",
        "\n",
        "# Iterate over the downloaded images\n",
        "for file_name in os.listdir(dataset_path):\n",
        "    image_path = os.path.join(dataset_path, file_name)\n",
        "\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Perform image processing operations on the image as needed\n",
        "    # Example: Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Example: Apply a threshold to create a binary image\n",
        "    _, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Perform further processing or analysis on the image\n",
        "\n",
        "    # Display the processed image\n",
        "    cv2.imshow('Processed Image', binary_image)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # Clean up resources\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "IP_KrePbsAqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "00417d5e-ed2b-4862-faf2-db2d463ec29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-4d4c684a683e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lkihjh777'\u001b[0m  \u001b[0;31m# Replace with the name of the Kaggle dataset you want to download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#api.dataset_download_files(dataset_name, path=dataset_path, unzip=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Download the dataset archive with the ID 'lkihjh777' to the directory 'D:\\Kaggle dataset archive.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mdataset_download_files\u001b[0;34m(self, dataset, path, force, quiet, unzip)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A dataset must be specified'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         owner_slug, dataset_slug, dataset_version_number = self.split_dataset_string(\n\u001b[0m\u001b[1;32m   1431\u001b[0m             dataset)\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Capturing image from webcam to be classified to the By the trained model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X5iW97oecjqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Capture an image from the webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "ret, frame = cap.read()\n"
      ],
      "metadata": {
        "id": "hEA6UWRPndEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess the image\n",
        "image = cv2.resize(frame, (224, 224))\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Classify the image using the trained model\n",
        "prediction = model.predict(image)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "\n",
        "# Release the webcam\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "I3U2I8VSchV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload to Github"
      ],
      "metadata": {
        "id": "8d6WFJ5F0PZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SJa-638/test-robot.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxtDdwFQ4nvF",
        "outputId": "3020109a-bce0-487f-81dc-57c333e8a89b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'test-robot'...\n",
            "remote: Enumerating objects: 2570, done.\u001b[K\n",
            "remote: Total 2570 (delta 0), reused 0 (delta 0), pack-reused 2570\u001b[K\n",
            "Receiving objects: 100% (2570/2570), 59.33 MiB | 18.98 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n",
            "Updating files: 100% (2316/2316), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SJa-638/test-robot.git"
      ],
      "metadata": {
        "id": "y4E2X9E_3v9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a94fd4-6cb3-490f-8eb8-da0e1e6873ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'test-robot' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"SJa-638\"\n",
        "!git config --global user.email \"sazab638@gmail.com\"\n",
        "\n",
        "\n",
        "# Navigate to the cloned repository directory\n",
        "%cd '/content/test-robot'\n",
        "\n",
        "# Upload the notebook to the cloned repository\n",
        "!git add .\n",
        "!git commit -m \"Add notebook\"\n",
        "\n",
        "# Push the changes to the remote repository\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRRG-5yz46f0",
        "outputId": "9a98627b-374c-4a6c-bebf-7b6938a5f0c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/test-robot\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_dgz9wv56rx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}